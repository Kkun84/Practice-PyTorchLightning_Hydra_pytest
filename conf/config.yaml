defaults:
  - optimizer: Adam
  - lr_scheduler: Step

name: ''
seed: ~

hparams:
  batch_size: 64
  num_workers: 4
  lr: 0.001

model_params:
  hidden_dim: 32

optim:
  optimizer: ${optimizer}
  lr_scheduler: ${lr_scheduler}

trainer:
  gpus: 0
  num_nodes: 1

callback:
  checkpoint:
    class: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      filepath: ~
      monitor: val_loss
      verbose: False
      save_top_k: 3
      mode: auto
  early_stopping:
    class: pytorch_lightning.callbacks.EarlyStopping
    params:
      monitor: val_loss
      min_delta: 0
      patience: 10
      verbose: False
      mode: auto
  callbacks:
    ~

loggers:
  - class: pytorch_lightning.loggers.TensorBoardLogger
    params:
      save_dir: '.'
      name: ''
      version: ''
